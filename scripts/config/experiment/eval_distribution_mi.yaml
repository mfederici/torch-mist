# @package _global_
defaults:
  - override /mi_estimator: ???
  - override /data: multimixture

params:
  hidden_dims: [256, 128]

  # Discriminative estimator parameters
  neg_samples: 1
  k_dim: 64

  # Generative estimator parameters
  marginal_transform_name: spline_autoregressive
  joint_transform_name: spline_autoregressive
  conditional_transform_name: conditional_linear

  # Quantized estimator parameters
  n_bins: 32
  temperature: 0.1
  batch_size: 64

estimation:
  batch_size: ${params.batch_size}
  eval_batch_size: ${params.batch_size}
  valid_percentage: 0.1
  early_stopping: false
  lr_annealing: false
  max_epochs: 32
  device: ${device}
  optimizer_class:
    _target_: torch.optim.AdamW
    _partial_: true
